[{"title":"linux","url":"/2024/07/28/%E6%8A%80%E6%9C%AF/Linux%E7%9F%A5%E8%AF%86/","content":"gitgit clone下来的仓库就可以 git status查看记录\n对于github 私有仓库，使用PAT密钥方式\ngit clone 有时需要代理 GitHub Proxy 最新地址发布\ngit config --local user.emailgit config --local user.email &quot;lingshi321@gmail.com&quot;//设置自己的邮箱添加github网址代理git remote set-url origin https://ghfast.top/XXXgit remote -vgit switch -c v1_pd_yhc_debug origin/v1_pd_yhc_debug// 创建本地分支，同时追踪远程分支git pull  //拉取代码git push  //上传代码git status git add .git commit -m &quot;&quot;git fetch origin git branch -rgit branch -vvgit stash  //暂存git pullgit stash popgit config core.fileMode false      //忽略权限改变\nVScode插件：Git History 查看提交历史\n大模型下载Hugging Face很卡，得用镜像\nHF-Mirror\npip install -U huggingface_hubexport HF_ENDPOINT=https://hf-mirror.comhuggingface-cli download bigscience/bloom-560m --local-dir bloom-560m\n首页 · 魔搭社区 \nmodelscope download --model modelscope/Llama-2-13b-ms --local_dir Llama-2-13b\ntmux可以让命令保持在后台运行\ntmux new -s nametmux attach -t nametmux lstmux kill-session -t 0//鼠标上下滚动Ctrl + b 输入冒号: set -g mouse on//退出tmuxCtrl + b  d\n进程ps查找进程，grep搜索。\n容器里面看不到外面的进程。\nps aux | grep bashpkill -x python3pkill -x bash   \nctrl + C 中断， ctrl + Z 暂停，fg调到前台\n命令设置权限，解决无法修改，运行的问题\nchmod -R 777 filename  rm -rf *          //一定一定注意使用history\n其他本地用wsl2搭建Linux环境，配合VScode\npip换源，apt-get换源\n","tags":["技术","linux"]},{"title":"nsys profile","url":"/2025/03/23/%E6%8A%80%E6%9C%AF/nsys%20profile/","content":"111\n有 nsight system，nsight compute2个工具\nsystem可以exprot成数据库，然后用SQL语句对数据库进行分析。\n关键参数\n","tags":["技术","profile"]},{"title":"cuda知识","url":"/2025/02/25/%E6%8A%80%E6%9C%AF/cuda%E7%9F%A5%E8%AF%86/","content":"GPU参数SM（Streaming Multiprocessor）GPU的核心计算单元，一个GPU含有多个SM\n每个SM包含：\n\nCUDA核心（SP, Streaming Processor）：最基本的计算单元，执行浮点和整数运算\n共享内存（Shared Memory）：SM内线程块可共享的高速内存\n寄存器（Registers）：为每个线程分配私有存储\n调度器（Warp Scheduler）：管理线程束（Warp）的执行\n\nThread、Block、GridBlock：包含多个Thread，同一Block内的线程共享SM资源（如Shared Memory）\nGrid：包含多个block\nWarp（线程束）：GPU的最小调度单位，固定包含32个线程\n每个Block最多包含1024个Thread（受硬件限制）\nBlock大小建议设为32的倍数（与Warp对齐，避免资源浪费）\n每个 Block 会被分配到一个 SM 上执行，一个 SM 可以同时执行多个 Block\nCUDA核函数使用__global__修饰，通过&lt;&lt;&lt;grid_dim, block_dim&gt;&gt;&gt;指定执行配置\ngrid，block 支持1D/2D/3D索引（dim3），用索引来识别对应的计算任务\n__global__ void vectorAdd(const float *A, const float *B, float *C, int N) &#123;    int i = blockIdx.x * blockDim.x + threadIdx.x;    if (i &lt; N) &#123;        C[i] = A[i] + B[i];    &#125;&#125;vectorAdd&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(d_A, d_B, d_C, N);\n在CUDA核函数中，第一个参数通常是 output\nGPU结构INT32 ：32位整型运算的器件\nFP32 : 32位浮点型计算 \nTensor Core: 矩阵运算\n\n资料\nNvidia 显卡架构详解 – Twisted Meadows （比较GPU的方法）\n","tags":["技术","cuda"]},{"title":"多机训练","url":"/2024/01/03/%E6%8A%80%E6%9C%AF/%E5%A4%9A%E6%9C%BA%E8%AE%AD%E7%BB%83/","content":"多机训练一个节点NODE_RANK=0，另一个节点NODE_RANK=1\n设置网卡，MASTER_ADDR (要写成网址,不能写成localhost ！)\n两边手动启动就不用ssh免密登录\n#!/bin/bashexport CUDA_DEVICE_MAX_CONNECTIONS=1export GLOO_SOCKET_IFNAME=ens5f0export TP_SOCKET_IFNAME=ens5f0GPUS_PER_NODE=4# Change for multinode configMASTER_ADDR=192.168.1.101MASTER_PORT=13466NUM_NODES=2NODE_RANK=0WORLD_SIZE=$(($GPUS_PER_NODE*$NUM_NODES))VOCAB_FILE=./need/gpt2-vocab.jsonMERGE_FILE=./need/gpt2-merges.txtDISTRIBUTED_ARGS=(    --nproc_per_node $GPUS_PER_NODE     --nnodes $NUM_NODES     --master_addr $MASTER_ADDR     --master_port $MASTER_PORT    --node_rank $NODE_RANK )GPT_MODEL_ARGS=(    --num-layers 8    --hidden-size 1024    --num-attention-heads 8     --seq-length 2048    --max-position-embeddings 2048    --num-experts 8    --moe-token-dispatcher-type alltoall    --disable-bias-linear)TRAINING_ARGS=(    --micro-batch-size 1     --global-batch-size 16     #--rampup-batch-size 16 16 5859375     --train-iters 5     --weight-decay 0.1     --adam-beta1 0.9     --adam-beta2 0.95     --init-method-std 0.006     --clip-grad 1.0     --bf16    --lr 6.0e-5     --lr-decay-style cosine     --min-lr 6.0e-6    --lr-warmup-fraction .001     --lr-decay-iters 430000 )MODEL_PARALLEL_ARGS=(\t--tensor-model-parallel-size 1 \t--pipeline-model-parallel-size 1     --expert-model-parallel-size 4      #--sequence-parallel )DATA_ARGS=(    #--data-path $DATA_PATH     --mock-data    --vocab-file $VOCAB_FILE     --merge-file $MERGE_FILE     --split 100,0,0)EVAL_AND_LOGGING_ARGS=(    --log-interval 1     --save-interval 10000     --eval-interval 1000     #-save $CHECKPOINT_PATH     #--load $CHECKPOINT_PATH     --eval-iters 0    #--tensorboard-dir $TENSORBOARD_LOGS_PATH )torchrun $&#123;DISTRIBUTED_ARGS[@]&#125; pretrain_gpt.py \\    $&#123;GPT_MODEL_ARGS[@]&#125; \\    $&#123;TRAINING_ARGS[@]&#125; \\    $&#123;MODEL_PARALLEL_ARGS[@]&#125; \\    $&#123;DATA_ARGS[@]&#125; \\    $&#123;EVAL_AND_LOGGING_ARGS[@]&#125;  \\    2&gt;&amp;1 | tee need/gpt.log     \n\n[ ] 一个脚本启动2个机器\n\nray常用命令\nray start --headray statusray stop\n","tags":["技术","多机训练"]},{"title":"并行策略","url":"/2023/11/20/%E6%8A%80%E6%9C%AF/%E5%B9%B6%E8%A1%8C%E7%AD%96%E7%95%A5/","content":"简介主要针对transformer模型架构，megatron-LM框架。\n输入input X维度 （batch_size, sequence, hidden_size) （b, s, h)\n资料\nNVIDIA/Megatron-LM   官网里面给出了经典的3篇文章\n常见的分布式并行策略 - OneFlow\n并行技术 | Colossal-AI (colossalai.org)\n数据并行DP从 b维度进行切分。要 all-reduce 互相传梯度。\nzero1 对于 optimizer states 的切分。每个gpu只维护一部分优化器状态，也只更新一部分参数。这样显存和计算都减少了。\n\n通信量并没有增加。Ring AllReduce就是分为两个步骤：reduce-scatter和 all-gather。\n通信量：$2\\times (N-1)  \\times  \\frac{K}{N} $    k是数据大小，N个GPU\n资料\nRing AllReduce简介 \n张量并行TP从h维度切分。attention层一个GPU放几个head。只要在g处做all-reduce加在一起就行。\n先做一个列并行，再做一个行并行。\n\n列并行:把权重A按照列来分割。\n\n行并行:把权重A按照行分割成两部分。\n\nsequence parallelsp从s维度切分。all-reduce变成all-gather和reduce-scatter。通信g是前向的all-gather，反向reduce-scatter，$\\hat{g}$相反。同样通信量也没有增加。\n具体是 layernorm 和 dropout 按sequence维度拆分。这2个层可以序列并行，因为layernorm是一个token一个token算的。\n\nsp也可以用到attention层，但会引入通信，适用场景是长序列输入。\n流水线并行Gpipe。算完前向再算反向。\n\n1F1B、交错流水线 。上面是1F1B，保持进行中的微批次数量里只有4个（与管道深度一样），这样相比Gpipe显存会更小。\nlayers 16，pp4配置下。1F1B划分：1-4，5-8，9-12，13-16。交错流水线可以1-2，9-10；3-4，11-12；5-6，13-14；7-8，15-16这样划分，可以理解为先把模型划分成几块（2块），再依次划分给GPU。这样需要更多轮1234才能算完（2次）一个前（反）向，但是时间也相应减小了，使得bubble占比更小。\n\nmoe专家并行基于 Transformer 的 MoE，即将 Transformer 中的 MLP 层替换为 MoE 层。其他操作没变。\n从数据并行到专家并行需要转化切分维度，做all-to-all操作。\n在megatron中，是用all-gather、reduce-scatter实现all-to-all功能的。\n\n","tags":["技术","并行策略"]},{"title":"transformer","url":"/2023/11/01/%E6%8A%80%E6%9C%AF/transformer/","content":"embedding维度大小是（v,h），v是词表总量，h是hidden_size。 每个词有个整数索引，embedding后就是对应索引的那行，python代码中张量直接套一个索引就得出了。megatron：并行是按v维度划分，分别存储weight的一部分，再all-gather得到完整的输出，但是代码中用mask置0，维度没变，所以是用all-reduce加在一起。\nself-attention能提取序列的关系，取代了之前的RNN，方便并行。\n由input a1分别算出q，k，v。attention就是每个词之间的关系，q1乘其他词的k得到，最后拿attention乘对应的v 再加起来，就是output b1。要训练的就是Wq,Wk,Wv。\nmuti-head就是多个self-attention，可以提取不同角度的信息。\n资料\nTransformer - YouTube   讲的很清楚\n","tags":["技术","transformer"]},{"title":"推理","url":"/2024/04/05/%E6%8A%80%E6%9C%AF/%E6%8E%A8%E7%90%86/","content":"111\nvLLM关键参数\nserver端\n--max-num-batched-tokens 2048 \\     \\\\一个batch最多token数--max-num-seqs 256 \\                \\\\一个batch最多请求req数量\nclient端\n--ignore-eos \\--burstiness 100 \\     请求分布\nKV cacheKV-cache 缓存，token -&gt; token 生成下一个token需要当前的Q，和之前所有的KV。\n资料\nLLM推理入门指南②：深入解析KV缓存 (qq.com)\nHow a Transformer works at inference vs training time - YouTube\n","tags":["技术","推理"]},{"title":"硬件知识","url":"/2024/03/13/%E6%8A%80%E6%9C%AF/%E7%A1%AC%E4%BB%B6%E7%9F%A5%E8%AF%86/","content":"CPU取数据CPU依次从 cache、主存、磁盘中读取数据。cache中没有，如果主存中有，读取后会写入到cache中。但主存中也没有，则会用DMA从磁盘读取到主存中，而不是CPU直接读取磁盘。\nframe是物理内存一个块的大小，page是虚拟内存，一般二者相等。\n硬件NIC 网卡\n随机访问存储器RAM（Random Access Memory） /DDR/ HBM 都是内存\nPCIe switch  就是一个接口拓展，把硬件连接起来\nPCIe总线连接CPU和其他外设，比如GPU，网卡等\n资料\nPCIe（一） —— 基础概念与设备树 | Soul Orbit (r12f.com)\nNVLinkNVLink 是 GPU 和 CPU 之间的高速连接通道，第四代 NVLink 速度高达每秒 900GB/s，是PCIe 5.0 带宽的 7 倍多。\nRDMA跨机直接访问内存的技术，会减少开销\n资料\n【最新】Nvidia GPU互联技术全景图 - 知乎 (zhihu.com)\n","tags":["技术","硬件"]},{"title":"个人成长","url":"/2023/01/01/%E7%94%9F%E6%B4%BB/%E4%B8%AA%E4%BA%BA%E6%88%90%E9%95%BF/","content":"\n  463f9e316d1170d91999ca3c1874fb1b47a389aed5c30f8c2093a9ce7b7b25dcee63a3bba0cbec59b21dd7058931faf04016274c8665e0e4d06bc3d82f1f3352816d6a20c77bc7148048dd9a3b7d770b289ad865b0b5813b697e284ac8aff49d20b7e5dd136fc07091e07e5eadc9fee31e6901685fc359acef7341ca4b3f88d8ebb448ffeef0ba26a8597d6cb9c7b995823b8dc4cae83d388a498dc7bc6537da60b513c3aae385683fc494dd546f19ae7fb19ea7ff42104a7b9c7310eaf0409ecc152310164ed937d9c948630915535aaf7f61dff3b496bccd20fc01b9604266fdf352bb1ea609083106db7d376516bb70f146bcccfdee94b69d4b9313faa1461f560c37064ff838a5eb6e4db027fb2e5cbc0c203bb31d4ffedbf9dc9b7f88a4bc417ab6d79e79518fe600d51f50a00743be38ba9caac38f67d40c894ca542d0ede9d34a29d905667d74e34bde9be30ef306ed980a00f0ef88f4420ef55aa92c9f2159d2f352475963535717c803b4f5801b5b703f11e59fca6afc6dfbd39f4ee815ff1de69c390e827b2be37f717ec7e2c5e24cf2491f8ca5f14bac491ad1b1871ab5209a63f3fa08a38e782d2d2bd738d24630b9f1a954d479cb2a1138133827b360521f093ab0b78772b887824e3e389cab47545d765db674485d812396829f0513f2f911eb395834fe2b16826d0dfec47c47848700668c115fa53565e236c6042ad92a935cad01d2a3dcf07f26f21094c23a1db53ec106b28207f61d4836cf8bb2d60b10c4e0b77ea688b7c1c5e9d5dec7bedd4bc9f823099835435b38610010ea7862bc263e6f344deab7223c19e4d550a332c9b65a4d2afed1e813f1e02385046be9e89f904e7bc767cc31f7db6c3d406851724b40df8aa0d76cfe26f39a223c9479d82bd27902162d4f11f4cbf43d88d4554c7b476d50a21ddcb5465d85413ad192fe510f80cc040f91c95334b72281e5c7eb8048f8d37998314fec419a11b46ea6614120b7f4d44d66eeeb3e9a32df47e65ee66848df6f89ffbeefa78c5a09fe1ea8169c77ded211ec1850faaa82f0cdcdae4cad5147bc64de44e1ede10878f230e667a66a7a56607a5886c4483af833b62ed079ab1f5ab9d150dbeaebd8f239e779bfd0531be3c2ee045f2e3fbf3ba8b6f4b8c00126a117d177288a0e4dda639cad8865845db5fc3e78499806f15bafc98f565554bb88c783222fdffb3519c37119acbeac1371b37f5e1d0a3daabb975b1b0e406bb6a2589806facf02f9c7deba9dd060a30637aab0318c4f6072054b2be69c6720f0f664e63377c9fee333a200b81c9302923ca76b11b93fa3ff593481a8d5243573faec82ecb6410d4f743f2d37a4057b1a2c3e4cddae1cda054aa51d405a7dbfa977f3f4efd3ab18e767c87a9886ad03a7fb133f691a1e7f7eabba5b63b9c23d489d49717b6edae6b82fd6b1c02e418a8683f2eb1d0236f0cb7a0d7255548980037ad47727f069f75b6e34e1f8accd308c41e169f390027513a614c5e6e8656ddb7d3b622e4e4952dc83a42d3c56d8a3fe873eeb10d0c49a22ed87f5b69a5458795f0f3a9639ddb5ce3ef8b0d9d6851210fd50672a8d63782dbe148d588be9fc78ebef48b5a5778be9fcdccc01cabd046631626e3d7bf3bfbc4413ab6336fdeeb7dba12eec3f5c26ae6f04fe52898d0ee99db90e4507cdac4be4315800c46a0f654fbf387bc9de6fec826ae508e75136e9d4de86f5053a951d2d903cc7c81a2d3173633fd3eeef3688d117686521f3a68e4e4cb3c334490a37a75c589499469537f476bfe63f13d25bf37d583e342614e83ec2a4c1d6ba7ff73d9161aed0541b40c52e0372dddb1a8eb9b583fb09b6d8b0820c93e8eba6d02e89ae2dd6d7fc3c1542d414da1b4812e65acfd722e960c8681d21d9bc111ca44a6339dc71623dc21709a9e798b56e8eec919b708c05114ee477ec56457b3a3adc2861954bcd73cde73c32dc986cf8e34b28d4b17789f1038406a680cc567bdbded2ad976cf47b0e3bfea3c4ddd655755c82544cef7081f10291603e7e7da347c8d66f37b497dd4aabb6595d426629132690f013e03b4f6eb21c5d0284a3c577a70fd9e7734e288feec0f470e06eedad3d17d862846a3943fab6e071b396938b63734816db34bbbe406b7cef8c72834263bc89bea52c5eaf2d6bf0d5f80c7239c9172305b1771c25da12940695928b943c72015f9f0e4bf0d795331aaa39c9b20283ed5d76737817ab9eea084cfd7a70649bf8ebd4bdd2d0843b142bd152dc603ffacac565d74febb7d1305cbd6d1a093562e74d789cdc05acff4d4c35fb64cdb787ab8a25c790f90bc630e785f89c61faad294e4f303bffd37c66bc4afff971ef99fe0635bb413493fb13b9e64946\n  \n    \n      \n      \n        请输入密码后查看\n      \n    \n  \n\n","tags":["生活","private"]},{"title":"个人设备","url":"/2025/03/16/%E7%94%9F%E6%B4%BB/%E4%B8%AA%E4%BA%BA%E8%AE%BE%E5%A4%87/","content":"\n111\n应用v2ray clash vpn\nlistray 搜索工具\nSnipaste 截图放在桌面上\nzotero 论文管理\n设备无线鼠标、无线键盘很方便\n投屏笔记本电脑是可以盖上再投票的\n\n","tags":["生活","小妙招"]},{"title":"哲学思想","url":"/2023/01/02/%E7%94%9F%E6%B4%BB/%E5%93%B2%E5%AD%A6%E6%80%9D%E6%83%B3/","content":"\n  463f9e316d1170d91999ca3c1874fb1bafeffb428b0c40ef5707938beebbd788e3d73d94ab606f04a423d4ba7b287006a10611108d48cd559c85b667630ec80835655baf905de1543a3298a302e5127373fb8cce0efa7d4a7c70840fd279070b7a5301ade292f460638208de4df8d03f352ecd199328d66ff5cd9169c8a3f4a8764342ca9b9bbfbefcae3f574470316b8d8a5ea431425301af602afaf48dcaa418c314da867884cb15a6ef6eef5048c7211661337506722ff87f2baf20d6b4eb\n  \n    \n      \n      \n        请输入密码后查看\n      \n    \n  \n\n","tags":["生活","private"]},{"title":"经济学常识","url":"/2025/04/07/%E7%94%9F%E6%B4%BB/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%B8%B8%E8%AF%86/","content":"111\n经济常识\n这几天美国加关税，搞得很热闹。\n关税\n提高进口商品的价格，使本土生产的同类产品在价格上更具竞争力，从而为国内制造业提供了一定的保护。\n降息（加息），借钱和存钱的利率都会降低（增加）\n降息\n\n刺激经济 ：企业贷款成本降低，更愿意投资扩产；消费者贷款（如房贷、车贷）更便宜，促进消费。\n风险资产价格上升： 低利率环境通常会推动股市和其他风险资产的价格上涨，但同时也可能引发资产泡沫。\n通胀压力增加： 降息可能导致市场上货币供应量增加，如果供给跟不上需求，可能会引发通胀上升。\n\n加息\n\n减小通胀： 加息可以提高借贷成本，从而抑制投资和消费需求，防止通胀加剧。\n防范金融风险： 通过提高利率，可以降低过度杠杆化风险，防止资产泡沫形成。\n\n杠杆效应 是指利用借款来放大投资收益。然而，借款过多（即过度杠杆化）时，一旦市场出现不利变化，投资者或企业的偿债能力可能不足，导致违约和金融风险累积。低利率环境下，融资成本较低，企业和个人更容易通过借款来增加投资或消费，从而推动杠杆水平的不断提高。\n资产泡沫的成因： 在低利率环境下，投资者为了获得更高的回报，往往会投入大量资金到股市、房地产等资产市场，导致这些资产价格远远偏离其内在价值。\n通胀率通胀率通常反映的是一个国家经济中物价水平的平均上涨幅度。通胀并非越低越好，温和通胀（2-3%）通常被视为经济健康的标志。\n","tags":["生活","经济"]},{"title":"芙莉莲","url":"/2023/05/09/%E7%94%9F%E6%B4%BB/%E8%8A%99%E8%8E%89%E8%8E%B2/","content":"前言初中时看魔戒、霍比特人给我印象很深，很喜欢那种一行人冒险的故事（人类勇士，法师，矮人，精灵），自由的探险风景又很好。芙莉莲风格类似，同时富有深度，记录下感想。\n人是需要被肯定的活在社会中，总体也算善良正义。我们都希望自己的一生是有所贡献，值得肯定的呀。\n\n所以当他人愿意说出自己的事迹，不要吝啬赞美，要给出肯定啊。\n\n人的心灵是很脆弱的，需要一些支撑，要不然也不会出现那么多宗教。这里的女神大人，应该是希望有个客观的‘神“来评判自己的一生。\n心理暗示人们大都需要积极的心理暗示。但是就算没拔出勇者之剑，老子依旧要去干倒魔王的勇气真的好可贵！\n还是要专心做事吧，之前的种种并不代表什么，比如啥高考成绩、被谁谁谁肯定/否定等。做事的时候仅仅是在做这件事而已，不要给自己太多心理暗示，如一定能做成（做不成）。\n\n","tags":["生活","芙莉莲"]},{"title":"Megatron-LM","url":"/2023/10/19/%E6%8A%80%E6%9C%AF/%E7%BB%93%E6%9D%9F/Megatron-LM/","content":"运行英伟达的并行框架，很常用。\ngpt需要vocab，merges 2个文件，预处理数据，补充sh脚本里的参数，如GPUS_PER_NODE、tp、pp。\n运行命令：\nbash examples/pretrain_gpt.sh \n\ncheckpoint可以不保存，直接注释掉，—load、—save\n—mock-data 可以生成假数据，需要注释掉 —data-path \n\nA402024/7/30 用最新的megatron代码，最新的docker镜像，运行很顺利。\ndocker run -it --name ydshi_8_2 --gpus all --shm-size=64G -v /home/ydshi/data:/workspace nvcr.io/nvidia/pytorch:24.04-py3 /bin/bash\n用 Megatron-LM 训练一个 GPT-2 | Nólëbase (ayaka.io)   数据集来源\n1080Ti由于架构比较老，需要注释掉trans engine模块，加上参数   —transformer-impl local \ndocker run -it --name ydshi_3_1 --gpus all --shm-size=1G -v /home/ydshi/data:/workspace nvcr.io/nvidia/pytorch:22.04-py3 /bin/bash\n显存不够CUDA out of memory，可以减小一些参数。\n​    —num-layers 12 \\​    —hidden-size 256  \n统计nccl通信占比在interation 代码前后插入 torch.cuda.nvtx.range_push   、 …pop tag。运行时前面加上nsys profile，在windows 使用NsightSystems 进行可视化查看。（一般第一个iteration是warm up，可以设置成5、10）\n\n下载并安装师兄改版的pyprof。在megatron-LM/result中\n使用 myrun.sh 将nsys文件转化成 csv表格。在可视化文件中复制iteration的信息（要找default stream），如图。\nName\tStart\tDuration\tTID\tGPU\tContextDescription of the event [968.163 ms]\t18.0755s\t968.163 ms\t117199\tGPU 1\tStream 7\n复制到interation.py, 再改下文件名，运行interation.py这个就行，\n会调用到algo.py ，统计kernel时间的。\nmyrun.shnsys profile bash examples/pretrain_gpt_distributed_with_mp.sh &gt; record.txt nsys stats --report=sqlite  pp4.nsys-reppython3 -m pyprof.parse pp4.sqlite &gt; pp4.jsonpython3 -m pyprof.prof --csv -c idx,kernel,sil,device,stream,start,end,grid,block pp4.json &gt; pp4.csv\n","tags":["技术","Megatron"]},{"title":"docker","url":"/2024/04/09/%E6%8A%80%E6%9C%AF/%E7%BB%93%E6%9D%9F/docker%E7%8E%AF%E5%A2%83/","content":"docker-v挂载数据，工作目录命名为workspace。\n直接用宿主机的空间和网络。（方便跨机）\ndocker run -it --name ydshi_loongserve --gpus all --ipc=host --net=host -v /nfs/ydshi:/workspace loongserve:latest /bin/bash\n创建完容器之后重新打开\ndocker start ydshidocker exec -it ydshi /bin/bash \n将容器保存为镜像，传输docker 镜像\ndocker commit abc123 my_image:latestdocker save -o my_image.tar my_image:latestscp my_image.tar root@192.168.0.1:/pathdocker load -i my_image.tar \n查看镜像        docker images   \n查看容器        docker ps \n删除镜像        docker rmi\n删除容器        docker rm\n有时候容器用不了GPU，nvidia-smi 也看不到。尝试：\ndocker restart container           \ncuda环境pytorch，cuda要兼容。 \ncuda版本。nvidia-smi看到的cuda version比较奇怪\nnvcc --version\npytorch依赖的cuda版本\npython -c &quot;import torch; print(torch.version.cuda)&quot;\ncuda工具包一般在 /usr/local/  cuda\n心得vscode下载ssh插件，打开服务器的文件夹\nVScode插件：Dev Containers 连接到容器内部，可以查看库函数\nAttach to Running Container…\ndocker也可以用  conda  来管理环境的，不过默认在用base。\n","tags":["技术","linux","docker"]},{"title":"博客使用","url":"/2022/09/02/%E6%8A%80%E6%9C%AF/%E7%BB%93%E6%9D%9F/%E5%8D%9A%E5%AE%A2%E4%BD%BF%E7%94%A8/","content":"介绍hexo+keep主题，部署在github的静态网站。 \n我需要的博客功能\n\n代码折叠，数学公式，简洁美观。\n\nGit Bash进入博客目录中（d:\\blog，d:\\blog\\source\\_posts都行）。\n常用命令：\nhexo clean  # 清除缓存hexo g      # 生成静态网页hexo s      # 启动服务器，本地查看hexo d      # 部署到Github\n加密\n用密码访问，在github仓库能看到。Hexo加密   \n\n放在_draft文件夹，就只能在本地查看，不会上传。\n\n\n图床typora+picgo-github图床，picgo要打开时间戳重命名。\ntypora的图片统一复制到本地文件夹，如typora/img。博客中的图片就手动上传。\n图片还是别压缩了。\n下载compress插件，搭配压缩网站（tinify.com)  。   \n数学公式如何在 hexo 中支持 Mathjax  这个实测简单好使\n浏览器需要安装插件：TeX All the Things\ntips1修改仓库,这样hexo d好使点\nrepository: git@github.com:shiyandong/shiyandong.github.io.git#repository: https://github.com/shiyandong/shiyandong.github.io.git\ntips2git bash默认的框太丑了，也不能缩放。得集成到windows terminal\n","tags":["技术","blog"]},{"title":"深度学习基础","url":"/2023/12/01/%E6%8A%80%E6%9C%AF/%E7%BB%93%E6%9D%9F/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/","content":"常用方法Cross Entropy Loss交叉熵主要用于度量两个概率分布间的差异性。标签值 y（分类时用one-hot编码，真实类别是1，其他为0）， 预测值 a，分类数n\n\n\\text { loss }=-\\sum_{j=1}^n y_j \\ln a_jsoftmax多类别分类的激活函数，将一组实数转化为表示概率分布的值。每个元素都在 0 到 1 之间，且所有元素的和为 1。\n给定输入向量 $z=\\left(z_1, z_2, \\ldots, z_k\\right)$ ，计算公式为:\n\n\\begin{aligned}\n\\sigma(z)_i=\\frac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}，i=1,2, \\ldots, k\n\\end{aligned}其中， $e$ 是自然对数的底， $k$ 是类别的数量。\nlarynorm\n用于加速训练的。对单个样本的不同特征做归一化操作，公式：\n\n\\begin{aligned}\n\\mu_i & =\\frac{1}{n} \\sum_{j=1}^n x_{i j} \\\\\n\\sigma_i^2 & =\\frac{1}{m} \\sum_{j=1}^m\\left(x_{i j}-\\mu_i\\right)^2 \\\\\n\\hat{x}_{i j} & =\\frac{x_{i j}-\\mu_i}{\\sqrt{\\sigma_i^2+\\epsilon}}\n\\end{aligned}\n\\begin{aligned}\n\n\n \\end{aligned}dropout用于防止神经网络过拟合。在训练过程中，随机地将一部分神经元的输出设置为零。\n资料\n03.2 交叉熵损失函数 - AI-EDU (microsoft.github.io)\n优化器深度学习的优化目标是最小化目标（损失）函数，就是反向传播算梯度从而更新参数。不同优化器区别在于q函数。\n待优化参数: $\\theta$ ，目标函数： $f(\\theta)$ ，学习率: $\\alpha$\n $\\mathrm{t}$ 时刻参数的梯度: $g_t=\\nabla f\\left(\\theta_t\\right)$\n优化通式：  $\\theta_t=\\theta_{t-1}-q\\left(g_t\\right)$\nSGDSGD的梯度下降过程，类似于一个小球从山坡上滚下，它的前进方向只与当前山坡的最大倾斜方向一致(梯度反方向)，每一个时刻的初速度都为０。\n\n\\begin{aligned}\n\n\\theta_t=\\theta_{t-1}-\\alpha * g_t\n\n \\end{aligned}SGD容易收敛到局部最优，在某些情况下可能被困在鞍点。\n引入 Momentum \n\n\\begin{aligned}\n\nm_t & =\\text { momentum } * m_{t-1}+\\alpha * g_t \\\\\n\\theta_t & =\\theta_{t-1}-m_t\n\n\\end{aligned}假设momentum =0.9,$ \\alpha=0.01$, 有:\n\n\\begin{aligned}\n& m_5=0.9 m_4+0.01 g_5 \\\\\n& m_4=0.9 m_3+0.01 g_4 \\\\\n& m_3=0.9 m_2+0.01 g_3 \\\\\n& m_2=0.9 m_1+0.01 g_2\n\\end{aligned}则: $m_5=0.01 *\\left(g_5+0.9 g_5+0.9^2 g_3+0.9^3 g_2+0.9^4 g_1\\right)$可以看到第5次更新的梯度包含了前4次的梯度，且是一个指数衰减的过程。\nSGD Momentum的梯度下降过程，前进方向由当前山坡的最大倾斜方向与之前的下降方向共同决定，小球具有初速度(动量)。\nAdam\n\\begin{aligned}\nm_t & =\\beta_1 m_{t-1}+\\left(1-\\beta_1\\right) g_t \\\\\n\\hat{m}_t & =\\frac{m_t}{1-\\beta_1^t} \\\\\nV_t & =\\beta_2 V_{t-1}+\\left(1-\\beta_2\\right) g_t^2 \\\\\n\\hat{V}_t & =\\frac{V_t}{1-\\beta_2^t} \\\\\n\\alpha_t & =\\frac{\\alpha}{\\sqrt{\\hat{V}_t}+\\epsilon} \\\\\n\\theta_t & =\\theta_{t-1}-\\alpha_t * \\hat{m}_t    \\\\\n\n\\end{aligned}二阶动量$V_t $ 是历史梯度平方和，度量历史更新频率。参数更新越频繁，二阶动量越大，学习率就越小。$\\hat{m}_t 、\\hat{V}_t$是偏差修正。\n资料\noptimizer优化器总结 - weber’s Blog (haiping.vip)\n反向传播就是求损失函数C对参数的梯度，利用梯度更新参数。\n反向计算梯度时，根据前向不同的计算公式，从而有相应的系数。\n资料 \nBack Propagation and Gradient Calculation in Deep Learning (hannlp.github.io)\n下篇 反向传播的微积分原理_哔哩哔哩_bilibili\n卷积神经网络(CNN)反向传播算法 - 刘建平Pinard - 博客园 (cnblogs.com)\nconv2d结构Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) \n这个卷积层参数：$64\\times3\\times9+64 = 1792$  \n一个通道的结果： 输入的3个通道各自经过一个卷积核再相加得到的，卷积核个数=输出通道*输入通道，每个通道还有有一个偏置。 \n资料\n卷积操作参数量和计算量       卷积核图示\n","tags":["技术","深度学习"]},{"title":"运动","url":"/2025/05/31/%E7%94%9F%E6%B4%BB/%E8%BF%90%E5%8A%A8/","content":"篮球把球转到横纹，投篮会更准\n正常防守右手球员，用左手防。\n打球时不要和对手杠上，没意义，得找友善，素质好的人一起玩。\n投篮力量有点不够，得把篮球贴紧手掌才行\n眼镜打篮球时可以带上运动眼镜，右眼400，左眼425。\n\n","tags":["生活","运动"]}]